# Architecture HM-Drive - Syst√®me de Stockage Distribu√©

## Introduction

HM-Drive est le syst√®me de fichiers distribu√© au c≈ìur d'Hypermedia. Il fournit une infrastructure r√©siliente pour le stockage, la synchronisation et l'acc√®s aux m√©dias sur des instances locales et distantes.

### Inspirations architecturales

- **Git** : versioning, delta sync, int√©grit√© par checksums
- **Syncthing** : synchronisation P2P, r√©silience, d√©centralisation
- **IPFS** : adressage par contenu (content-addressable storage)
- **Dropbox/Drive** : synchronisation s√©lective, cache local

### Objectifs cl√©s

1. **R√©silience** : fonctionnement en mode d√©grad√© lors de d√©connexions
2. **Performance** : cache intelligent, transferts incr√©mentaux
3. **Int√©grit√©** : v√©rification cryptographique (BLAKE2b)
4. **Portabilit√©** : compatible Linux, macOS, Windows

---

## Architecture de l'Instance

### Structure d'une instance HM-Drive

```
instance_root/
‚îú‚îÄ‚îÄ config.yaml           # Configuration instance
‚îú‚îÄ‚îÄ database.db           # SQLite avec m√©tadonn√©es
‚îú‚îÄ‚îÄ cache/                # Cache local
‚îÇ   ‚îú‚îÄ‚îÄ thumbnails/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 128x128/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 256x256/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 512x512/
‚îÇ   ‚îî‚îÄ‚îÄ metadata/
‚îú‚îÄ‚îÄ collections/          # Dossier principal (m√©dias locaux)
‚îÇ   ‚îú‚îÄ‚îÄ collection1/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ media001.jpg
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ media002.mp4
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ .index        # Index local (optionnel)
‚îÇ   ‚îî‚îÄ‚îÄ collection2/
‚îî‚îÄ‚îÄ subscriptions/        # Copies locales des abonnements
    ‚îú‚îÄ‚îÄ remote1_collection_a/
    ‚îî‚îÄ‚îÄ remote2_collection_b/
```

### Fichier config.yaml

```yaml
instance:
  id: "local-instance-uuid"
  name: "My Workstation"
  uri: "hm://localhost:8080"
  type: "local"

storage:
  root: "/data/hypermedia"
  max_size: "500GB"
  cache_size: "10GB"

network:
  listen_address: "0.0.0.0"
  listen_port: 8080
  tls_enabled: true
  cert_path: "certs/server.crt"
  key_path: "certs/server.key"

subscriptions:
  auto_sync: true
  sync_interval: 900  # secondes (15min)
  conflict_strategy: "last_write_wins"
  bandwidth_limit: "10MB/s"

media:
  supported_formats:
    images: ["jpg", "jpeg", "png", "webp", "gif"]
    videos: ["mp4", "webm", "mov", "avi"]
    audio: ["mp3", "wav", "flac", "ogg"]
  generate_thumbnails: true
  thumbnail_sizes: [128, 256, 512]
  compute_checksums: true
```

---

## Mod√®le de Collections

### Structure arborescente

Les collections forment une hi√©rarchie arborescente illimit√©e :

```
root
‚îú‚îÄ‚îÄ projects/
‚îÇ   ‚îú‚îÄ‚îÄ 2024/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ january/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ february/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ march/
‚îÇ   ‚îî‚îÄ‚îÄ 2025/
‚îú‚îÄ‚îÄ archive/
‚îî‚îÄ‚îÄ shared/
    ‚îú‚îÄ‚îÄ public/
    ‚îî‚îÄ‚îÄ private/
```

### M√©tadonn√©es de collection

```json
{
  "id": "uuid",
  "name": "January 2024",
  "path": "projects/2024/january",
  "parent_id": "uuid-parent",
  "description": "Photos et vid√©os du mois de janvier",
  "icon": "üì∏",
  "tags": ["work", "2024"],
  "created_at": "2024-01-01T00:00:00Z",
  "updated_at": "2024-01-31T23:59:59Z",
  "media_count": 342,
  "total_size_bytes": 4294967296
}
```

### Liens symboliques virtuels

Stockage en base de donn√©es (pas de vrais symlinks syst√®me) :

```python
# Cr√©ation d'un lien
drive.create_link(
    source="portraits/favorites",
    target="archive/2024/best-of",
    type="alias"
)

# Acc√®s transparent
media_list = drive.list_media("portraits/favorites")
# ‚Üí Liste les m√©dias de "archive/2024/best-of"
```

**Types de liens** :
- `alias` : r√©direction compl√®te (comme un symlink)
- `shortcut` : acc√®s rapide (conserve l'identit√© source)
- `related` : association s√©mantique (suggestion)

---

## Syst√®me d'URI Unifi√©

### Format canonique

```
hm://[instance]/[collection_path]/[media_id][#fragment][?params]
```

### Composants

| Composant | Description | Exemple |
|-----------|-------------|----------|
| `instance` | Nom ou adresse de l'instance | `local`, `server.com`, `192.168.1.100:8080` |
| `collection_path` | Chemin hi√©rarchique | `projects/2024/january` |
| `media_id` | Identifiant unique (UUID ou checksum tronqu√©) | `abc123def456` |
| `fragment` | R√©f√©rence temporelle/spatiale | `#t=30s`, `#xywh=100,200,300,400` |
| `params` | Param√®tres additionnels | `?quality=high&format=webp` |

### Exemples d'URI

```
# M√©dia local
hm://local/landscapes/mountain001

# M√©dia distant
hm://studio.example.com:8080/shared/video.mp4

# Avec fragment temporel (vid√©o)
hm://local/tutorials/demo.mp4#t=30s,45s

# Avec fragment spatial (image)
hm://local/photos/panorama.jpg#xywh=100,200,300,400

# Composant d'un composite
hm://local/projects/composite_main#component=2

# Avec param√®tres
hm://local/portraits/photo.jpg?quality=high&thumbnail=256
```

### R√©solution d'URI

```python
from hypermedia import URIResolver

resolver = URIResolver(drive)

# Parsing
components = resolver.parse("hm://local/projects/abc123#t=30s")
# ‚Üí URIComponents(instance='local', collection='projects', 
#                   media_id='abc123', fragment='t=30s')

# R√©solution
media = resolver.resolve("hm://local/projects/abc123")
# ‚Üí Objet Media avec path, m√©tadonn√©es, etc.

# Construction
uri = resolver.build_uri(
    instance="server.com",
    collection="shared/videos",
    media_id="xyz789",
    fragment="t=10s"
)
# ‚Üí "hm://server.com/shared/videos/xyz789#t=10s"
```

---

## Architecture Distribu√©e

### Types d'instances

**Instance principale (primary)**
- R√©f√©rence canonique pour certaines collections
- G√®re les modifications ma√Ætresses
- Peut servir plusieurs instances secondaires

**Instance secondaire (secondary)**
- Abonn√©e √† une ou plusieurs instances principales
- Mode lecture seule ou lecture-√©criture selon config
- Synchronisation pull (r√©ception uniquement)

**Instance pair (peer)**
- √âgalit√© avec d'autres pairs
- Synchronisation bidirectionnelle
- Pas de hi√©rarchie

### Topologies support√©es

**√âtoile (Star)**
```
      Primary
     /   |   \
   S1   S2   S3
```
Une instance principale, N secondaires en pull.

**Maill√©e (Mesh)**
```
   P1 ‚Äî‚Äî‚Äî P2
    |    X    |
   P3 ‚Äî‚Äî‚Äî P4
```
Instances pairs avec sync bidirectionnelle.

**Hybride**
```
     Primary
     /     \
   P1  ‚Äî  P2
    |       |
   S1      S2
```
Combinaison √©toile + maillage.

### D√©couverte d'instances

**M√©thode manuelle**
```yaml
subscriptions:
  - name: "Studio Server"
    uri: "hm://studio.example.com:8080"
    collections: ["projects/*", "assets"]
```

**D√©couverte mDNS/Zeroconf (LAN)**
```python
from hypermedia.network import InstanceDiscovery

discovery = InstanceDiscovery()
instances = discovery.scan(timeout=5)
# ‚Üí [{'name': 'MacBook-Pro', 'uri': 'hm://192.168.1.50:8080'}, ...]
```

**Registry centralis√© (optionnel)**
```python
registry = InstanceRegistry("https://registry.hypermedia.io")
registry.register(drive.instance)
instances = registry.search(tags=["studio", "public"])
```

---

## Abonnements (Subscriptions)

### Modes d'abonnement

**Pull (mono-directionnel Local ‚Üê Remote)**
- Instance locale r√©cup√®re depuis distante
- Lecture seule sur la source
- Cas d'usage : backup, mirror, consultation

**Push (mono-directionnel Local ‚Üí Remote)**
- Instance locale envoie vers distante
- Mise √† jour distante automatique
- Cas d'usage : publication, deployment

**Sync (bi-directionnel Local ‚Üî Remote)**
- Synchronisation compl√®te dans les 2 sens
- Gestion des conflits n√©cessaire
- Cas d'usage : collaboration, multi-device

### Configuration d'abonnement

```yaml
subscription:
  name: "Studio Sync"
  remote_uri: "hm://studio.example.com:8080"
  collections:
    - "projects/2024"
    - "assets/shared"
  mode: sync  # pull | push | sync
  schedule: "*/15 * * * *"  # Cron: toutes les 15min
  conflict_strategy: last_write_wins
  bandwidth_limit: "10MB/s"
  filters:
    include_tags: ["published", "approved"]
    exclude_tags: ["draft", "private"]
    min_size: "100KB"
    max_size: "100MB"
```

### Cr√©ation programmatique

```python
from hypermedia import SyncManager, SyncMode, ConflictStrategy

sync_mgr = SyncManager(drive)

sub_id = sync_mgr.subscribe(
    remote_uri="hm://backup-server.local",
    collections=["projects/2024", "archive"],
    mode=SyncMode.BIDIRECTIONAL,
    schedule="0 * * * *",  # Toutes les heures
    conflict_strategy=ConflictStrategy.MERGE_METADATA,
    config={
        "bandwidth_limit": "5MB/s",
        "include_tags": ["important"],
        "retry_on_error": True,
        "max_retries": 3
    }
)

# Synchronisation imm√©diate
result = sync_mgr.sync_now(sub_id)
print(f"Ajout√©s: {result.media_added}, Mis √† jour: {result.media_updated}")
```

---

## Synchronisation et R√©silience

### Algorithme de synchronisation

**Phase 1 : Discovery (D√©couverte)**
```python
# R√©cup√©ration liste distante
remote_media = client.list_media(collection_id, with_checksums=True)

# Comparaison avec liste locale
local_media = drive.list_media(collection_id)

# Identification des diff√©rences
deltas = calculate_deltas(local_media, remote_media)
# ‚Üí [{'action': 'add', 'media': ...}, {'action': 'update', ...}]
```

**Phase 2 : Delta Calculation (Calcul des diff√©rences)**
```python
def calculate_deltas(local, remote):
    local_by_checksum = {m.checksum: m for m in local}
    remote_by_checksum = {m.checksum: m for m in remote}
    
    deltas = []
    
    # Ajouts (pr√©sent remote, absent local)
    for checksum, media in remote_by_checksum.items():
        if checksum not in local_by_checksum:
            deltas.append({'action': 'add', 'media': media})
    
    # Mises √† jour (checksums identiques, m√©tadonn√©es diff√©rentes)
    for checksum in set(local_by_checksum) & set(remote_by_checksum):
        local_m = local_by_checksum[checksum]
        remote_m = remote_by_checksum[checksum]
        if local_m.updated_at < remote_m.updated_at:
            deltas.append({'action': 'update', 'media': remote_m})
    
    # Suppressions (pr√©sent local, absent remote)
    for checksum in set(local_by_checksum) - set(remote_by_checksum):
        deltas.append({'action': 'delete', 'checksum': checksum})
    
    return deltas
```

**Phase 3 : Transfer (Transfert)**
- Transfert des fichiers manquants (rsync-like)
- Compression √† la vol√©e (zstd)
- V√©rification checksums apr√®s transfert
- Barre de progression

**Phase 4 : Reconciliation (R√©conciliation)**
- Application atomique des changements
- Mise √† jour base de donn√©es
- Invalidation du cache
- Logs de synchronisation

### Gestion des conflits

**Strat√©gies disponibles**

**1. Last Write Wins**
```python
def resolve_last_write_wins(local, remote):
    return remote if remote.updated_at > local.updated_at else local
```

**2. Merge Metadata (fusion intelligente)**
```python
def resolve_merge_metadata(local, remote):
    merged = local.copy()
    merged.tags = list(set(local.tags + remote.tags))  # Union
    merged.descriptors = local.descriptors + remote.descriptors
    merged.updated_at = max(local.updated_at, remote.updated_at)
    return merged
```

**3. Version Both (conservation des 2 versions)**
```python
def resolve_version_both(local, remote):
    # Renommer le local
    local.filename = f"{local.stem}_local{local.suffix}"
    # Garder le remote avec nom original
    return [local, remote]
```

**4. Manual (r√©solution manuelle)**
```python
def resolve_manual(local, remote):
    raise ManualResolutionRequired({
        'local': local,
        'remote': remote,
        'diff': compute_diff(local, remote)
    })
```

### Mode d√©connect√©

**Queue de synchronisation**
```python
class SyncQueue:
    def enqueue(self, subscription_id, operation, data):
        """Ajoute une op√©ration √† la queue persistante"""
        db.add_to_sync_queue(
            subscription_id=subscription_id,
            operation=operation,  # 'add', 'update', 'delete'
            target_uri=data['uri'],
            data_json=json.dumps(data),
            status='pending'
        )
    
    def process_queue(self, subscription_id):
        """Traite toutes les op√©rations en attente"""
        operations = db.get_sync_queue(subscription_id, status='pending')
        
        for op in operations:
            try:
                execute_operation(op)
                db.update_sync_queue_status(op.id, 'success')
            except NetworkError:
                # Retry plus tard
                op.attempts += 1
                if op.attempts >= op.max_attempts:
                    db.update_sync_queue_status(op.id, 'failed')
```

**D√©tection de reconnexion**
```python
from hypermedia.network import NetworkMonitor

monitor = NetworkMonitor()

@monitor.on_reconnect
def handle_reconnect():
    print("R√©seau r√©tabli, traitement de la queue...")
    for sub in drive.get_active_subscriptions():
        sync_mgr.queue.process_queue(sub.id)
```

---

## Cache Local

### Architecture du cache

```
cache/
‚îú‚îÄ‚îÄ thumbnails/
‚îÇ   ‚îú‚îÄ‚îÄ 128x128/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [checksum_8_premiers_chars].jpg
‚îÇ   ‚îú‚îÄ‚îÄ 256x256/
‚îÇ   ‚îî‚îÄ‚îÄ 512x512/
‚îú‚îÄ‚îÄ metadata/
‚îÇ   ‚îî‚îÄ‚îÄ [checksum].json
‚îî‚îÄ‚îÄ previews/
    ‚îî‚îÄ‚îÄ [checksum]_preview.mp4
```

### Politique de cache

```python
class CacheManager:
    def __init__(self, cache_dir, max_size=10*1024**3):  # 10GB
        self.cache_dir = cache_dir
        self.max_size = max_size
        self.lru = LRUCache()
    
    def evict_if_needed(self):
        current_size = get_directory_size(self.cache_dir)
        if current_size > self.max_size:
            # √âviction LRU
            while current_size > self.max_size * 0.9:  # 90%
                oldest = self.lru.pop_oldest()
                if oldest.is_local:
                    continue  # Ne jamais √©vincer les m√©dias locaux
                os.remove(oldest.path)
                current_size -= oldest.size
```

### Pr√©-fetching intelligent

```python
def prefetch_adjacent_media(current_media_id, collection_id, count=5):
    """
    Pr√©charge les m√©dias adjacents pour navigation fluide.
    """
    media_list = drive.list_media(collection_id)
    current_index = media_list.index_of(current_media_id)
    
    # Pr√©charger count m√©dias avant et apr√®s
    for i in range(max(0, current_index - count), 
                   min(len(media_list), current_index + count + 1)):
        media = media_list[i]
        if not cache.has(media.checksum):
            cache.prefetch(media, priority='low')
```

---

## Performance et Optimisation

### Indexation

```sql
-- Index critiques pour performance
CREATE UNIQUE INDEX idx_media_checksum ON media(checksum);
CREATE INDEX idx_media_collection ON media_collections(collection_id);
CREATE INDEX idx_media_created ON media(created_at DESC);
CREATE INDEX idx_tags_name ON tags(name);

-- Index full-text (SQLite FTS5)
CREATE VIRTUAL TABLE media_fts USING fts5(
    media_id UNINDEXED,
    filename,
    metadata_text
);
```

### Parall√©lisation

```python
from concurrent.futures import ThreadPoolExecutor, as_completed

def batch_import_media(file_paths, collection_id, workers=4):
    """
    Import parall√®le de m√©dias.
    """
    with ThreadPoolExecutor(max_workers=workers) as executor:
        futures = {
            executor.submit(drive.add_media, collection_id, path): path
            for path in file_paths
        }
        
        results = []
        for future in as_completed(futures):
            try:
                media = future.result()
                results.append(media)
            except Exception as e:
                print(f"Erreur import {futures[future]}: {e}")
        
        return results
```

### Benchmarks cibles

| Op√©ration | Cible | Mesure |
|-----------|-------|--------|
| Import 1000 images (10MB avg) | < 30s | Avec checksums + thumbnails |
| Scan collection 10k m√©dias | < 2s | Liste avec m√©tadonn√©es de base |
| Sync 10GB (LAN 1Gbps) | < 5min | Delta sync, compression |
| Recherche full-text sur 100k | < 100ms | Avec FTS5 index√© |
| G√©n√©ration thumbnail | < 500ms | Image 4K ‚Üí 256x256 |

---

## H√©ritage de prompt-imagine

### Concepts r√©utilis√©s

‚úÖ **Checksums BLAKE2b** : d√©tection de doublons, int√©grit√©  
‚úÖ **Collections arborescentes** : organisation hi√©rarchique  
‚úÖ **Thumbnails multi-r√©solution** : performance affichage  
‚úÖ **M√©tadonn√©es enrichies** : prompts ‚Üí d√©finisseurs pond√©r√©s  
‚úÖ **Orphan manager** : d√©tection et correction incoh√©rences  
‚úÖ **Transactions atomiques** : robustesse des op√©rations  

### Am√©liorations apport√©es

‚ú® **Distribution et synchronisation** : multi-instances (nouveau)  
‚ú® **URI unifi√©s** : adressage global (nouveau)  
‚ú® **Cache multi-niveaux** : performance acc√®s distants (nouveau)  
‚ú® **Mode d√©connect√© r√©silient** : queue persistante (nouveau)  
‚ú® **Liens symboliques virtuels** : navigation flexible (nouveau)  
‚ú® **API REST standardis√©e** : interop√©rabilit√© (nouveau)  

---

## Conclusion

L'architecture HM-Drive fournit une infrastructure solide pour le stockage et la synchronisation distribu√©e de m√©dias. La combinaison de checksums cryptographiques, d'une synchronisation incr√©mentale intelligente et d'un cache multi-niveaux garantit √† la fois **performance** et **r√©silience**.

Les concepts √©prouv√©s de prompt-imagine (checksums, collections, m√©tadonn√©es enrichies) sont pr√©serv√©s et √©tendus avec des capacit√©s de distribution moderne, faisant d'HM-Drive une solution adapt√©e aux workflows collaboratifs et multi-devices.

**Prochaine √©tape** : Architecture HM-Scene pour la mise en sc√®ne et la navigation dynamique.
